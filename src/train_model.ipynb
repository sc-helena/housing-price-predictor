{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "\n",
    "from src.config import DATASET\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(DATASET)  # saved in cache\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "\n",
    "def load_housing_data():\n",
    "    # loaded to pandas\n",
    "    return pd.read_csv(os.path.join(path, \"housing.csv\"))\n",
    "\n",
    "\n",
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_corr(data):\n",
    "    # Select only the numeric columns\n",
    "    numeric_data = data.select_dtypes(include=[float, int])\n",
    "\n",
    "    # Calculate the correlation matrix on the numeric data\n",
    "    corr_matrix = numeric_data.corr()\n",
    "    corr_matrix[\"median_house_value\"].sort_values(ascending=False)\n",
    "    # Display the correlation matrix\n",
    "    print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"rooms_per_house\"] = housing[\"total_rooms\"] / housing[\"households\"]\n",
    "housing[\"bedrooms_ratio\"] = housing[\"total_bedrooms\"] / housing[\"total_rooms\"]\n",
    "housing[\"people_per_house\"] = housing[\"population\"] / housing[\"households\"]\n",
    "\n",
    "print_corr(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from utils.figures import save_fig\n",
    "\n",
    "housing.reset_index()\n",
    "num_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"impute\", SimpleImputer(strategy=\"median\")),  # insert missing values\n",
    "        (\"scaler\", MinMaxScaler(feature_range=(-1, 1))),  # scale num values\n",
    "    ]\n",
    ")\n",
    "\n",
    "housing_num = housing.select_dtypes(include=[np.number])  # numeric values\n",
    "housing_num_tarnsformed_arrays = num_pipeline.fit_transform(housing_num)\n",
    "housing_num_transformed_df = pd.DataFrame(\n",
    "    housing_num_tarnsformed_arrays, columns=housing_num.columns, index=housing_num.index\n",
    ")\n",
    "\n",
    "\n",
    "# plot changes\n",
    "plt.rc(\"font\", size=14)\n",
    "plt.rc(\"axes\", labelsize=14, titlesize=14)\n",
    "plt.rc(\"legend\", fontsize=14)\n",
    "plt.rc(\"xtick\", labelsize=10)\n",
    "plt.rc(\"ytick\", labelsize=10)\n",
    "\n",
    "housing_num_transformed_df.hist(bins=50, figsize=(12, 8))\n",
    "save_fig(\"attribute_histogram_plots_after_scaling\")  # extra code\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat = housing[[\"ocean_proximity\"]]  # categorial attribute\n",
    "housing_cat.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One Hot encoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "# Convert to a NumPy array\n",
    "housing_cat_1hot_dense = housing_cat_1hot.toarray()\n",
    "# Get the feature names (categories) from the encoder\n",
    "categories = cat_encoder.get_feature_names_out(input_features=housing_cat.columns)\n",
    "# Convert to a pandas DataFrame\n",
    "housing_cat_1hot_df = pd.DataFrame(\n",
    "    housing_cat_1hot_dense, columns=categories, index=housing_cat.index\n",
    ")\n",
    "housing_transformed = pd.concat(\n",
    "    [housing_num_transformed_df, housing_cat_1hot_df], axis=1\n",
    ")\n",
    "print(housing_transformed[\"median_income\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed to ensure same output for multiple runs\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_seed = 3\n",
    "\n",
    "# ensure instances from each median income stratum\n",
    "housing_transformed[\"income_cat\"] = pd.cut(\n",
    "    housing_transformed[\"median_income\"],\n",
    "    bins=[-1.1, -0.6, -0.2, 0.2, 0.6, 1.1],\n",
    "    labels=[1, 2, 3, 4, 5],\n",
    ")\n",
    "\n",
    "housing_transformed[\"income_cat\"].value_counts().sort_index().plot.bar(rot=0, grid=True)\n",
    "plt.xlabel(\"Income category\")\n",
    "plt.ylabel(\"Number of districts\")\n",
    "plt.show()\n",
    "\n",
    "# use the stratisfied splitter\n",
    "strat_train_set, strat_test_set = train_test_split(\n",
    "    housing_transformed,\n",
    "    test_size=0.2,\n",
    "    stratify=housing_transformed[\"income_cat\"],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# income_cat not needed anymore\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from src.config import MODEL_PATH\n",
    "\n",
    "housing_labels_train = strat_train_set[\"median_house_value\"]\n",
    "model = TransformedTargetRegressor(LinearRegression(), transformer=StandardScaler())\n",
    "model.fit(strat_train_set[[\"median_income\"]], housing_labels_train)\n",
    "\n",
    "model_file_path = os.path.join(MODEL_PATH, \"price_estimator_model.pkl\")\n",
    "\n",
    "with open(model_file_path, \"wb\") as file:\n",
    "    dump(model, file, protocol=5)  # set protocol 5 to reduce memory usage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
